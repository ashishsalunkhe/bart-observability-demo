# ğŸš¦ BART Real-Time Observability Pipeline (GCP + OpenTelemetry)

A production-grade, real-time data engineering project that streams Bay Area Rapid Transit (BART) train data, processes it using GCP-native services, and adds deep observability using OpenTelemetry, Prometheus, Grafana, and Jaeger.

## ğŸ—‚ï¸ Project Structure

```
ğŸ“ bart-observability-pipeline/
â”œâ”€â”€ README.md
â”œâ”€â”€ terraform/                        # Infra-as-code for GCP resources
â”‚   â”œâ”€â”€ main.tf
â”‚   â”œâ”€â”€ variables.tf
â”‚   â””â”€â”€ outputs.tf
â”œâ”€â”€ cloud-functions/
â”‚   â””â”€â”€ ingest_bart_etd/             # Cloud Function to fetch and publish BART ETD
â”‚       â”œâ”€â”€ main.py
â”‚       â””â”€â”€ requirements.txt
â”œâ”€â”€ dataflow/
â”‚   â””â”€â”€ streaming_pipeline/
â”‚       â”œâ”€â”€ pipeline.py              # Apache Beam pipeline
â”‚       â”œâ”€â”€ pipeline_utils.py
â”‚       â””â”€â”€ requirements.txt
â”œâ”€â”€ observability/
â”‚   â”œâ”€â”€ otel-collector-config.yaml   # OpenTelemetry Collector config
â”‚   â”œâ”€â”€ grafana-dashboards/
â”‚   â””â”€â”€ prometheus-rules.yaml        # Alerting rules
â”œâ”€â”€ bigquery/
â”‚   â””â”€â”€ schemas/
â”‚       â””â”€â”€ bart_etd_schema.json
â”œâ”€â”€ dbt/
â”‚   â””â”€â”€ models/                      # Optional if using dbt for transformations
â”œâ”€â”€ docs/
â”‚   â”œâ”€â”€ architecture-diagram.png
â”‚   â””â”€â”€ lineage-overview.md
â””â”€â”€ scripts/
    â””â”€â”€ test_replay_pubsub.py        # Replay tool for testing
```

---

## ğŸ› ï¸ Tech Stack

- **Ingestion**: Cloud Scheduler + Cloud Functions + Pub/Sub
- **Processing**: Dataflow (Apache Beam)
- **Storage**: BigQuery, Cloud Storage (Parquet)
- **Observability**: OpenTelemetry, Prometheus, Jaeger, Grafana
- **Security**: IAM roles, service accounts, CMEK (optional)
- **CI/CD**: Terraform + GitHub Actions (to be added)

---

## ğŸ“ˆ Features

- ğŸš† Real-time ingestion of BART train data
- âš™ï¸ Streaming transformation with Dataflow
- ğŸ” End-to-end observability with OpenTelemetry
- ğŸ“¦ Metrics export to Prometheus and traces to Jaeger/Cloud Trace
- ğŸ“Š Grafana dashboards for latency, lag, and throughput
- ğŸ§ª Alerting on data freshness or pipeline issues
- ğŸ” Replay and backfill support
- ğŸ§° Schema registry + data validation (optional Avro/Protobuf)

---

## ğŸš€ Getting Started

### Prerequisites
- GCP account with billing enabled
- Enable APIs: Pub/Sub, Cloud Functions, Dataflow, BigQuery, Cloud Monitoring
- Python 3.8+

### Setup
```bash
# Clone the repo
$ git clone https://github.com/yourusername/bart-observability-pipeline.git
$ cd bart-observability-pipeline

# Deploy infra
$ cd terraform && terraform init && terraform apply

# Deploy Cloud Function
$ cd ../cloud-functions/ingest_bart_etd
$ gcloud functions deploy fetch_bart_etd --runtime python310 \
    --trigger-topic bart-etd --entry-point fetch_bart_etd

# Run Dataflow Job (Template or Direct Run)
$ python pipeline.py --runner=DataflowRunner ...
```

---

## ğŸ”’ Security Best Practices
- Use Workload Identity Federation
- Assign least-privilege roles to each component
- Optionally enable CMEK for GCS + BQ

---

## ğŸ“Š Observability Setup
- Deploy OpenTelemetry Collector on Cloud Run
- Configure Grafana to pull from Prometheus + Jaeger
- Use dashboards in `/observability/grafana-dashboards/`

---

## ğŸ“š Resources
- [BART API Docs](https://api.bart.gov/docs/etd/)
- [OpenTelemetry](https://opentelemetry.io/docs/)
- [Apache Beam](https://beam.apache.org/)
- [GCP Dataflow](https://cloud.google.com/dataflow)

---

## ğŸ“Œ TODOs
- [ ] Add dbt models for analytical use cases
- [ ] Add GitHub Actions CI/CD pipeline
- [ ] Add Looker Studio dashboard examples

---

## ğŸ“„ License
MIT License

---

## ğŸ‘¨â€ğŸ’» Author
Ashish Salunkhe | [ashishsalunkhe.com](https://ashishsalunkhe.com) | [LinkedIn](https://linkedin.com/in/ashishsalunkhe)
